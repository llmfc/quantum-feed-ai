# quantum-feed-ai

## About
This code was generated by [CodeCraftAI](https://codecraft.name)

**User requests:**
I want you to create me ChatGPT-like application. There's a prompt and user can talk to backend. User can choose between various LLMs (such as Gemini, OpenAI models, Claude, Llama - every model that exists). Once user's prompt is sent to backend, backend should pass that prompt to model and stream response back to user. Make sure to contain context (if user asks about topic X, backend responds, user probably wants to continue talking about same thing). Also, enable user to start new chat (clear context). For communication user python-openai package and focus on OpenAI compatible models. 

I want clear design with chat in focus, you can keep user's requests and responses it receives in browser's local storage. Also, emphasize to user the privacy is first, there's no KYC and that it's FREE.

Make sure to include deployment files as well.
- Style it a bit! I want nice CSS, to be almost exactly like ChatGPT. I know you're an artist, do something :D 

Also let customer select exact models: GPT 3.5, GPT 4.0, O1, LLama, Mistral, Gemini Flash 2.0, Gemini Pro 1.5 ...

Check OUTPUT.md for the complete unaltered output.

## Project Plan
```
 Estimate the effort required for each task in story points (1 story point = 8 hours).

Assume the following:

*   **LLM Provider Selection:**  Start with OpenAI and support Gemini as a second priority.  The architecture should be extensible to other providers later.
*   **Deployment Environment:** Docker Compose
*   **UI/UX Design:** Basic, functional interface. Focus on clarity and usability.
*   **Context Window Management:** Implement a fixed context window of 5 previous turns (prompts and responses). When the window is full, remove the oldest turn. No user configuration initially.
*   **Model Parameter Control:** Initially, only expose Temperature as a user-configurable parameter. Provide a simple slider in the UI.

## Project Plan: LLM Chat Application

**Project Goal:** Develop a functional LLM chat application using React (frontend) and Python (backend) with OpenAI and Gemini support, local storage for chat history, and no user accounts, deployed via Docker Compose.

**Guiding Principles:**

*   **Privacy First:** No user data stored server-side (except ephemeral session context).
*   **Extensible Design:**  Architecture should facilitate adding more LLM providers in the future.
*   **Iterative Development:**  Focus on core functionality first, then add features incrementally.

**Project Roles:** (Assumed for effort estimation purposes)

*   Frontend Developer
*   Backend Developer
*   DevOps Engineer

**Phase 1: Core Functionality (Sprint 1 & 2)**

**Sprint 1 (2 Weeks)**

| Task                                       | Description                                                                                                                                                              | Tech Considerations                                                                                                                                                                                                                                                                     | Effort (Story Points) | Assignee           |
| ------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------- | ------------------- |
| **Frontend: Basic Chat Interface (UI)**    | Create a basic chat interface with an input box for prompts, a display area for the chat history, a submit button, and an LLM selection dropdown (initially OpenAI).      | React, basic CSS.                                                                                                                                                                                                                                                                      | 5                      | Frontend Dev       |
| **Frontend: Temperature Slider**           | Add a slider control for adjusting the temperature parameter.                                                                                                                | React, potentially a UI component library for the slider.                                                                                                                                                                                                                                     | 2                      | Frontend Dev       |
| **Frontend:  `localStorage` Integration** | Implement functionality to store the chat history in `localStorage` and retrieve it on page load.                                                                         | JavaScript, browser `localStorage` API.                                                                                                                                                                                                                                                        | 3                      | Frontend Dev       |
| **Backend: OpenAI API Integration**        | Develop an API endpoint in Python that receives a prompt, passes it to the OpenAI API, and returns the response.  Implement streaming of the response back to the frontend. | Python, `python-openai` library, Flask/FastAPI (choose one), streaming using Server-Sent Events (SSE) or WebSockets.  API key management (using environment variables).                                                                                                                          | 8                      | Backend Dev        |
| **Backend: Basic Context Management**      | Implement a context management system that stores the last 5 turns (prompt and response) in memory for the current session.                                                   | Python dictionaries/lists to store conversation history.                                                                                                                                                                                                                                         | 3                      | Backend Dev        |
| **Docker Setup**                             | Create basic `Dockerfile` and `docker-compose.yml` files for local development.                                                                                             | Docker, Docker Compose.  Define necessary environment variables for the OpenAI API key.                                                                                                                                                                                                     | 3                      | DevOps Engineer  |
| **Project Setup & Documentation**            | Initialize the project, set up Git repository, and create basic documentation (README.md).                                                                             | Git, Markdown.                                                                                                                                                                                                                                                                            | 1                      | All                |

**Sprint 2 (2 Weeks)**

| Task                                       | Description                                                                                                                                                                                                                   | Tech Considerations                                                                                                                                                                                                     | Effort (Story Points) | Assignee           |
| ------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------- | ------------------- |
| **Frontend: API Integration & Streaming**  | Integrate the frontend with the backend API to send prompts and receive streamed responses.  Display the streamed responses in the chat interface.                                                                       | React, JavaScript's `fetch` API or a library like `axios`, handling SSE or WebSockets for streaming.                                                                                                                                | 5                      | Frontend Dev       |
| **Frontend: "New Chat" Button**            | Implement a "New Chat" button to clear the context and start a fresh conversation.                                                                                                                                           | React, simple button click handler.                                                                                                                                                                                   | 1                      | Frontend Dev       |
| **Backend: Gemini API Integration (Stub)** | Create a stub implementation for Gemini API integration.  This includes adding Gemini to the LLM selection in the backend and providing a placeholder response.  Full implementation will be done in the next phase.       | Python, structure to accommodate different API calls. No actual calls to the Gemini API.                                                                                                                               | 3                      | Backend Dev        |
| **Backend: Error Handling**                | Implement basic error handling in the backend to catch exceptions from the OpenAI API and provide informative error messages to the frontend.                                                                                | Python `try...except` blocks, logging, JSON error responses.                                                                                                                                                         | 3                      | Backend Dev        |
| **Backend: Refactor for LLM Abstraction**  | Refactor the backend code to start abstracting the LLM API calls to allow for easier integration of other LLMs in the future. Focus on defining interfaces and common data structures.                                     | Python, abstract classes/interfaces, common data model for prompts and responses.                                                                                                                             | 5                      | Backend Dev        |
| **Deployment Refinement**                | Refine the Docker setup, including setting up volumes for persistent storage and ensuring proper environment variable configuration.                                                                                       | Docker, Docker Compose.                                                                                                                                                                                             | 2                      | DevOps Engineer  |
| **Testing & Bug Fixes**                    | Perform thorough testing of the core functionality and fix any identified bugs.                                                                                                                                            | Manual testing, unit tests (optional for core components).                                                                                                                                                        | 5                      | All                |

**Phase 2: Enhanced Functionality (Sprint 3 & 4)**

**Sprint 3 (2 Weeks)**

| Task                                          | Description                                                                                                                                                                    | Tech Considerations                                                                                                                                                                    | Effort (Story Points) | Assignee           |
| --------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------- | ------------------- |
| **Frontend: Improved Error Handling**         | Implement more user-friendly error messages and visual indicators for errors on the frontend.                                                                                 | React, UI component library for displaying alerts or modals.                                                                                                                  | 2                      | Frontend Dev       |
| **Backend: Full Gemini API Integration**      | Implement full integration with the Gemini API, including authentication, prompt formatting, and response processing.                                                         | Python, API client for Gemini, handling different API structures compared to OpenAI.                                                                                    | 8                      | Backend Dev        |
| **Backend: Rate Limiting Handling**         | Implement mechanisms to handle rate limits from both OpenAI and Gemini APIs. Use retry logic with exponential backoff. Inform the user when rate limits are exceeded.             | Python, `requests` library with retry adapters, backoff algorithms, status code handling.                                                                              | 5                      | Backend Dev        |
| **Security Audit & Hardening**              | Review the codebase for potential security vulnerabilities and implement necessary hardening measures (e.g., input sanitization).                                                | Security best practices, static code analysis (optional).                                                                                                             | 3                      | Backend Dev        |
| **Deployment: CI/CD Pipeline Setup (Basic)** | Set up a basic CI/CD pipeline to automate the build and deployment process. This could use GitHub Actions or a similar service.                                            | GitHub Actions, Docker Hub (or other container registry).                                                                                                                    | 5                      | DevOps Engineer  |

**Sprint 4 (2 Weeks)**

| Task                                          | Description                                                                                                                                                               | Tech Considerations                                                                                                                                                                           | Effort (Story Points) | Assignee           |
| --------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------- | ------------------- |
| **Frontend: Improve Streaming UI**         | Enhance the UI for streaming responses, such as adding a loading indicator or displaying the response progressively.                                                      | React, CSS animations, potentially a UI component library for loading indicators.                                                                                                | 3                      | Frontend Dev       |
| **Backend: Unit Tests**                        | Write unit tests for critical backend components, such as the LLM API abstraction layer and the rate limiting logic.                                                      | Python `unittest` or `pytest`.                                                                                                                                                         | 5                      | Backend Dev        |
| **Documentation Update**                      | Update the documentation (README.md) with information about the supported LLMs, API keys, and deployment instructions.                                                     | Markdown.                                                                                                                                                                           | 2                      | All                |
| **Performance Optimization**                | Identify and address any performance bottlenecks in the application (both frontend and backend).                                                                            | Profiling tools, code optimization.                                                                                                                                                       | 3                      | All                |
| **Final Testing & Bug Fixing**                | Perform comprehensive testing of all features and fix any remaining bugs.                                                                                                 | Manual testing, automated testing (if feasible).                                                                                                                                    | 5                      | All                |
| **Deployment Finalization**                     | Finalize the deployment process and ensure the application is running smoothly in the target environment.  Implement monitoring to track the application health.           | Docker Compose, monitoring tools (e.g., Grafana, Prometheus - basic setup).                                                                                                      | 3                      | DevOps Engineer  |

**Technical Considerations Summary:**

*   **API Key Management:** Securely store and access API keys using environment variables or a secrets management solution.
*   **LLM API Abstraction:** Design a robust abstraction layer to handle the differences between LLM APIs.
*   **Streaming:** Implement streaming correctly for a responsive user experience.
*   **Rate Limiting:** Handle rate limits gracefully to avoid service disruptions.
*   **Error Handling:** Provide informative error messages to the user.
*   **Context Management:**  Ensure context is maintained across multiple turns.
*   **Security:** Follow security best practices to protect the application and user data.
*   **Scalability:** Consider scalability when designing the backend architecture (although not a primary focus for this initial project).

**Project Success Criteria:**

*   Functional chat application with OpenAI and Gemini support.
*   Local storage of chat history.
*   No user accounts or KYC.
*   Clean and extensible codebase.
*   Documented API.
*   Deployment via Docker Compose.

**Next Steps:**

1.  **Prioritize and refine tasks:** Confirm the priorities and refine the tasks with the development team.
2.  **Detailed Task Breakdown:** Break down each task into smaller, more manageable sub-tasks.
3.  **Resource Allocation:** Assign specific developers to each task.
4.  **Sprint Planning:** Hold sprint planning meetings to discuss the sprint goals and assign story points to each task.
5.  **Daily Stand-ups:** Conduct daily stand-up meetings to track progress and address any roadblocks.

This plan provides a structured approach to developing the LLM chat application. It emphasizes iterative development, flexibility, and a focus on delivering core functionality first. Regular communication and collaboration will be crucial for the project's success. Remember that the story point estimates are just estimates and may need to be adjusted as the project progresses. Good luck!

```
